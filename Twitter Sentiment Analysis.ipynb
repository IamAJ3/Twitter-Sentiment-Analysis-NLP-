{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4bbd48d21f3c12007cfe3acb969aacce513e881"
      },
      "cell_type": "code",
      "source": "dataset_train = pd.read_csv('../input/twitter-sentiment-analysis-for-hate-speech/Twitter Sentiment Train.csv', sep = ',' )\n#message for previous data cleaning method",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c243f61316876b3d71f93a0c2ea67fced22a4f8"
      },
      "cell_type": "code",
      "source": "#review = review.split()\nfrom nltk.corpus import stopwords",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbc43fe3f90562a246a45d374abbe2a4348e0439"
      },
      "cell_type": "code",
      "source": "from nltk.stem.porter import PorterStemmer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "950817b548c53fd50b06f8bab2eb921bbfe9a54c"
      },
      "cell_type": "code",
      "source": "#Stemming across data\nps = PorterStemmer()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a43b73ec10cbde518f6141cbbd67c06fec916057"
      },
      "cell_type": "code",
      "source": "dataset_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00456b7797716e3a67ce2b1dfa69ce00facdd792"
      },
      "cell_type": "code",
      "source": "#Creating Corpus\ncorpus = []\nfor i in range (0,31962) :\n    review = re.sub('[^a-zA-Z]', ' ', dataset_train['tweet'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    twitter_handle = ['user']\n    review = [word for word in review if not word in twitter_handle]\n    review = '  '.join(review)\n    corpus.append(review)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56990883585786f198981f86e9d49d456fcf831d"
      },
      "cell_type": "code",
      "source": "dataset_train['corpus'] = corpus\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b412721b175f37cad3926806213d4bc093061cb8"
      },
      "cell_type": "code",
      "source": "dataset_train['corpus']= dataset_train['corpus'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40862096e29e5be78f9c832df719f2def66ead47"
      },
      "cell_type": "code",
      "source": "all_words = ' '.join([ word for word in corpus])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb2f7f142b49697c6fe1b03f9968ce5a1b9a9ac8"
      },
      "cell_type": "code",
      "source": "from wordcloud import WordCloud\nwordcloud = WordCloud( width =800, height =500, random_state = 121, max_font_size = 110).generate(all_words)\n\nplt.figure(figsize = (10,7))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e8ed17114645888d7cdc24a04ebc9629522ccea"
      },
      "cell_type": "code",
      "source": "positive_words = ' '.join([text for text in dataset_train['corpus'][dataset_train['label'] == 0]])\nwordcloud = WordCloud( width =800, height =500, random_state = 121, max_font_size = 110).generate(positive_words)\n\nplt.figure(figsize = (10,7))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea5afcb5d2ff5b5eebacbcf4705722422777f4c3"
      },
      "cell_type": "code",
      "source": "negative_words = ' '.join([text for text in dataset_train['corpus'][dataset_train['label'] == 1]])\nwordcloud = WordCloud( width =800, height =500, random_state = 121, max_font_size = 110).generate(negative_words)\n\nplt.figure(figsize = (10,7))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "435c75c18713971b6134a806250c659e852ca612"
      },
      "cell_type": "code",
      "source": "# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(dataset_train['corpus']).toarray()\ny = dataset_train.iloc[:, 1].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a6f8c7e8418b887d1f8743dcbcbbc3e825b2bc1"
      },
      "cell_type": "code",
      "source": "from xgboost import XGBClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "935665fe9bbaac7c1b55cd9a1d3b20daad839d63"
      },
      "cell_type": "code",
      "source": "model = XGBClassifier(eta = 0.3, max_depth = 5)\nmodel.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61e81fc08998ce2ef0883eb7d2ed77852ac5b51f"
      },
      "cell_type": "code",
      "source": "y_pred_XGB = model.predict_proba(X_test) # predicting on the validation set\ny_pred_XGB = y_pred_XGB[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 than 1 else 0\ny_pred_XGB = y_pred_XGB.astype(np.int)\nfrom sklearn.metrics import f1_score\nf1_score(y_test, y_pred_XGB) # calculating f1 score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df29e7e642db4260bd4d0edd510119a212e0da74"
      },
      "cell_type": "code",
      "source": "#Trying tf-idf \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(max_df = 0.9, min_df = 2, max_features = 1500, stop_words = 'english')\n\nX_tfidf = tfidf_vectorizer.fit_transform(dataset_train['corpus'])\ny_tfidf = dataset_train.iloc[:, 1].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96a94bf95aab3a8a6e77cb54fbf3b275e651c418"
      },
      "cell_type": "code",
      "source": "from sklearn.cross_validation import train_test_split\nX_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size = 0.20, random_state = 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f93ab88551a7f8c48cc056831186118f62a9104"
      },
      "cell_type": "code",
      "source": "model_tfidf = XGBClassifier(eta = 0.3, max_depth = 10)\nmodel_tfidf.fit(X_train_tfidf, y_train_tfidf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80da277d0f6a668b3f3d2786105ad1d871b8702f"
      },
      "cell_type": "code",
      "source": "y_pred_XGB_tfidf = model_tfidf.predict_proba(X_test_tfidf) # predicting on the validation set\ny_pred_XGB_tfidf = y_pred_XGB_tfidf[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 than 1 else 0\ny_pred_XGB_tfidf = y_pred_XGB_tfidf.astype(np.int)\nfrom sklearn.metrics import f1_score\nf1_score(y_test_tfidf, y_pred_XGB_tfidf) # calculating f1 score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28efab9e9e6f7f1c6d0751c5e1fb871636a468a8"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}